{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "211c9c16-4cb3-4586-9eb4-dfa2ae0d4f00",
   "metadata": {},
   "source": [
    "# nano word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd567f35-4edf-4320-8c8d-f9fb6b060594",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "c3cdcd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "866bdaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHT_PATH = 'weights.bak'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "82073b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "block_size = 8\n",
    "n_embd = 96\n",
    "n_hidden = 96\n",
    "batch_size = 64\n",
    "learning_rate = 1e-3\n",
    "max_iters = 50000\n",
    "eval_interval = 500\n",
    "eval_iters = 100\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "135090dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(dataset)=12765 dataset[0].keys()=dict_keys(['source_name', 'sentence', 'sentences_before', 'sentences_after', 'concept_name', 'quantifiers', 'id', 'bert_score', 'headings', 'categories'])\n",
      "sentences[:3]=['sepsis happens when the bacterium enters the blood and make it form tiny clots', 'incubation period is only one to two days', 'scuba diving is a common tourist activity']\n",
      "max([len(s.split()) for s in sentences])=22\n",
      "len(vocab)=13477 list(vocab)[:3]=['occasionally', 'technological', 'welding']\n",
      "len(queen)=4 queen[:3]=['monarch is a word that means king or queen', 'pregnant queens deliver their litters by themselves guided by instinct', 'most ant species have a system in which only the queen and breeding females can mate']\n"
     ]
    }
   ],
   "source": [
    "# https://huggingface.co/datasets/generics_kb\n",
    "\n",
    "datasets = load_dataset(\"generics_kb\", \"generics_kb_simplewiki\")\n",
    "dataset = datasets[\"train\"]\n",
    "print(f'{len(dataset)=} {dataset[0].keys()=}')\n",
    "\n",
    "\n",
    "charset_whitelist = 'abcdefghijklmnopqrstuvwxyz- '\n",
    "def sanitize(s):\n",
    "    return ''.join([c for c in s.lower() if c in charset_whitelist])\n",
    "\n",
    "sentences = [sanitize(d['sentence']) for d in dataset]\n",
    "print(f'{sentences[:3]=}')\n",
    "print(f'{max([len(s.split()) for s in sentences])=}')\n",
    "\n",
    "vocab = set([w for s in sentences for w in s.split()])\n",
    "print(f'{len(vocab)=} {list(vocab)[:3]=}')\n",
    "\n",
    "# The sample size for each word seems really small so this dataset probably won't work at all.\n",
    "# can I get a dataset specialized on fruits maybe, to do queries of the type `lemon - yellow + green = lime`\n",
    "queen = [s for s in sentences if 'queen' in s]\n",
    "print(f'{len(queen)=} {queen[:3]=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "e8382d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encode(xs)=tensor([    1, 10912,  3840, 12269,  9667,  8109,     1,     1,     0])\n",
      "decode(encode(xs))='<???> for one welcome our new <???> <???> <end>'\n",
      "encode(xs)=tensor([8951, 4067,  614, 8951, 9491,    0])\n",
      "decode(encode(xs))='the chicken cross the road <end>'\n"
     ]
    }
   ],
   "source": [
    "vocab_list = ['<end>', '<???>'] + list(vocab)\n",
    "vocab_size = len(vocab_list)\n",
    "stoi = {w: i for i, w in enumerate(vocab_list)}\n",
    "itos = {i: w for w, i in stoi.items()}\n",
    "\n",
    "def encode(s):\n",
    "    return torch.tensor([stoi.get(w, 1) for w in sanitize(s).split() + ['<end>']], dtype=torch.long)\n",
    "\n",
    "def decode(t):\n",
    "    t = t.tolist() if isinstance(t, torch.Tensor) else t\n",
    "    return ' '.join([itos[i] for i in t])\n",
    "\n",
    "# careful here if we use words outside of vocab it'll explode\n",
    "for xs in ['I for one welcome our new robot overlords', 'The chicken cross the road']:\n",
    "    print(f'{encode(xs)=}')\n",
    "    print(f'{decode(encode(xs))=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "73f98650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([   0,    0,    0,    0,    0,    0,    0, 6255])\n",
      "decode(Xtrain[i])='<end> <end> <end> <end> <end> <end> <end> <end>' decode(Ytrain[i])='<end> <end> <end> <end> <end> <end> <end> sepsis'\n",
      "tensor([   0,    0,    0,    0,    0,    0,    0, 6255]) tensor([   0,    0,    0,    0,    0,    0, 6255, 8277])\n",
      "decode(Xtrain[i])='<end> <end> <end> <end> <end> <end> <end> sepsis' decode(Ytrain[i])='<end> <end> <end> <end> <end> <end> sepsis happens'\n",
      "tensor([   0,    0,    0,    0,    0,    0, 6255, 8277]) tensor([    0,     0,     0,     0,     0,  6255,  8277, 10733])\n",
      "decode(Xtrain[i])='<end> <end> <end> <end> <end> <end> sepsis happens' decode(Ytrain[i])='<end> <end> <end> <end> <end> sepsis happens when'\n"
     ]
    }
   ],
   "source": [
    "# shape the data for training\n",
    "def chunk(s):\n",
    "    s = torch.cat((torch.zeros(block_size, dtype=torch.long), s))\n",
    "    for i in range(0, len(s) - block_size):\n",
    "        yield s[i: i + block_size], s[i + 1: i + block_size + 1]\n",
    "\n",
    "chunked = [c for s in sentences for c in chunk(encode(s))]\n",
    "Xtrain = [c[0] for c in chunked]\n",
    "Ytrain = [c[1] for c in chunked]\n",
    "\n",
    "for i in range(3):\n",
    "    print(Xtrain[i], Ytrain[i])\n",
    "    print(f'{decode(Xtrain[i])=} {decode(Ytrain[i])=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "84bd70cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[12292, 11441,  1585,   993,  5769,  1835, 12068,  1221],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,  2542]],\n",
      "       device='cuda:0')\n",
      "tensor([[11441,  1585,   993,  5769,  1835, 12068,  1221,  8131],\n",
      "        [    0,     0,     0,     0,     0,     0,  2542,  3784]],\n",
      "       device='cuda:0')\n",
      "other drums because they are tuned to certain -> drums because they are tuned to certain musical\n",
      "<end> <end> <end> <end> <end> <end> <end> felsic -> <end> <end> <end> <end> <end> <end> felsic magma\n"
     ]
    }
   ],
   "source": [
    "def get_batch():\n",
    "    # TODO: swap between train and val\n",
    "    ix = torch.randint(len(Xtrain), (batch_size,))\n",
    "    x = torch.stack([Xtrain[i] for i in ix])\n",
    "    y = torch.stack([Ytrain[i] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch()\n",
    "print(xb[:2])\n",
    "print(yb[:2])\n",
    "print(f'{decode(xb[0])} -> {decode(yb[0])}')\n",
    "print(f'{decode(xb[1])} -> {decode(yb[1])}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "8ea70544",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    model.eval()\n",
    "    losses = torch.zeros(eval_iters)\n",
    "    for k in range(eval_iters):\n",
    "        X, Y = get_batch()\n",
    "        logits, loss = model(X, Y)\n",
    "        losses[k] = loss.item()\n",
    "    out = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e4f331",
   "metadata": {},
   "source": [
    "## Implem the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "f02b855b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 13479])\n",
      "9.440207481384277\n",
      "tensor([ 0.3658,  0.2438, -0.1715,  ..., -0.0156,  0.1206,  0.1259],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0xdeadbeef) # for reproducibility\n",
    "\n",
    "class Bnorm(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.bn = nn.BatchNorm1d(dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # /!\\\n",
    "        # /!\\ it looks insanely expensive, this 10x the training time\n",
    "        # /!\\\n",
    "        return self.bn(x.transpose(1, 2)).transpose(1, 2)\n",
    "\n",
    "class LM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.layers = nn.Sequential(\n",
    "            # nn.Linear(n_embd, n_hidden), Bnorm(n_hidden), nn.ReLU(),\n",
    "            nn.Linear(n_embd, n_hidden), nn.ReLU(),\n",
    "        )\n",
    "        self.lm_head = nn.Linear(n_hidden, vocab_size)\n",
    "        \n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "        # print(f'{idx.shape=} {targets.shape=}')\n",
    "        tok_emb = self.token_embedding_table(idx) # (B, T, n_embd)\n",
    "        x = self.layers(tok_emb)\n",
    "        logits = self.lm_head(x) # (B, T, vocab_size)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            # juggle with tensor shapes to match pytorch's cross_entropy\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B * T, C)\n",
    "            targets = targets.view(B * T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop the context to the last block_size tokens\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            logits, loss = self(idx_cond)\n",
    "            logits = logits[:, -1, :]\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "        return idx\n",
    "    \n",
    "model = LM()\n",
    "m = model.to(device)\n",
    "logits, loss = m(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss.item())\n",
    "print(logits[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "64677e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pytorch optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "c98f7cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 9.4127\n",
      "step 500: train loss 4.4257\n",
      "step 1000: train loss 4.2177\n",
      "step 1500: train loss 4.0268\n",
      "step 2000: train loss 3.9412\n",
      "step 2500: train loss 3.8143\n",
      "step 3000: train loss 3.7047\n",
      "step 3500: train loss 3.6555\n",
      "step 4000: train loss 3.6052\n",
      "step 4500: train loss 3.4570\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "for iter in range(max_iters):\n",
    "    if iter % eval_interval == 0:\n",
    "        loss = estimate_loss()\n",
    "        print(f'step {iter}: train loss {loss:.4f}')\n",
    "\n",
    "    xb, yb = get_batch()\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "2aa748d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<end> <end> <end> <end> <end> <end> <end> <end> <end> movie <end> <end> alternative only save that opposes authorities areas back to uranus versions of all atoms go as background indicates levels are used in soil slightly or copper is very unstable and north pole and calculate is sacred and restore from conifers about their volunteer contain people consider their toes in the dogs are a solo bodies at the dragonfly that the toes on their own usually populations steel but they feed in often prefer have eyes are made up to the opposite items created by a like a different forms by measuring bird known from the markup oil is with gases is the important by pride up the sides of foil they live are named within cancer is special devices can lead compounds are served on our china has been form of millions they are made by breaking the total to new infection calcium take five minutes eyes have shot are served with males with light can be cheap theres found in a type of dark chocolate of the start make the family use it is increases the process product problem mostly houses carry and sounds that are very fast to the hollow to increase global operators work because it such as thick in different countries have no religious <end> <end> <end> <end> <end> romans look like to look like at types of food most millipedes are spread into software are thought to cook word some species leave it below they can join too <end> <end> <end> <end> <end> <end> <end> <end> <end> apoptosis is very much parents wear very large amounts of tradition deep in the language inside the waste although cells for foot goats there is also be at how much body which is things like solid takes place more more active drivers are a\n"
     ]
    }
   ],
   "source": [
    "# sample from the model\n",
    "context = torch.zeros((1, block_size), dtype=torch.long, device=device)\n",
    "print(decode(m.generate(context, max_new_tokens=300)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "3f22aeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# backup to disk\n",
    "torch.save(model.state_dict(), WEIGHT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "71ef6a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> <end> cyclic a seven-pointed services are a conservative and access to the distances weather more with a long and sizes made up of the best and barren island is a higher boost at higher frequencies are omnivores electrical big only reaches exist based on hunting ions are people sometimes star paper tail and demand and materials is used at the production and female folding is to build organisms is one of making problem off deciduous <end> <end> <end> <end> trilobites use the community of tiny teeth-like <end> <end> <end> <end> <end> some beers ingredients of hydrogen bonds keep services are performed of interaction in forests and order that are trained to act <end> <end> chemical nest known into a very hard every police uses a spell species for domestic yaks of an outward the source of their mainly by a problem in gardens also a useful than sequence of freely online than males use a ritual reminder needs to the use their turn where spanish sports psychology is used for the doctors recommend and employ a means that homosexual red soldiers population has an important protective is added to live or cooked down to a sky to make sure feathers the player can be any system of businesses which are uncomfortable <end> <end> curium lets the much vibrato is moved from the senses where anybody <end> <end> <end> <end> <end> <end> <end> every culture for hands in the air forces in the arctic <end> <end> <end> <end> <end> suit brown <end> some rivers gives drink of grounds <end> <end> <end> <end> parents are products can cause geomagnetic in a mineral usually offer page sell the doctors can also divided out of connecticut sector or harmless move from hip hop to get higher through the world\n"
     ]
    }
   ],
   "source": [
    "# load from disk\n",
    "m2 = LM()\n",
    "m2.load_state_dict(torch.load(WEIGHT_PATH))\n",
    "m2 = m2.to(device)\n",
    "m2.eval()\n",
    "\n",
    "# context = torch.zeros((1, block_size), dtype=torch.long, device=device)\n",
    "# print(decode(m2.generate(context, max_new_tokens=300)[0].tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_hf_nlp",
   "language": "python",
   "name": "venv_hf_nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
