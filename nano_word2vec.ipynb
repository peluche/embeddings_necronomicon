{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "211c9c16-4cb3-4586-9eb4-dfa2ae0d4f00",
   "metadata": {},
   "source": [
    "# nano word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd567f35-4edf-4320-8c8d-f9fb6b060594",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3cdcd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "82073b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "block_size = 10\n",
    "batch_size = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "135090dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(dataset)=12765 dataset[0].keys()=dict_keys(['source_name', 'sentence', 'sentences_before', 'sentences_after', 'concept_name', 'quantifiers', 'id', 'bert_score', 'headings', 'categories'])\n",
      "sentences[:3]=['sepsis happens when the bacterium enters the blood and make it form tiny clots', 'incubation period is only one to two days', 'scuba diving is a common tourist activity']\n",
      "max([len(s.split()) for s in sentences])=22\n",
      "len(vocab)=13477 list(vocab)[:3]=['occasionally', 'technological', 'welding']\n",
      "len(queen)=4 queen[:3]=['monarch is a word that means king or queen', 'pregnant queens deliver their litters by themselves guided by instinct', 'most ant species have a system in which only the queen and breeding females can mate']\n"
     ]
    }
   ],
   "source": [
    "# https://huggingface.co/datasets/generics_kb\n",
    "\n",
    "datasets = load_dataset(\"generics_kb\", \"generics_kb_simplewiki\")\n",
    "dataset = datasets[\"train\"]\n",
    "print(f'{len(dataset)=} {dataset[0].keys()=}')\n",
    "\n",
    "\n",
    "charset_whitelist = 'abcdefghijklmnopqrstuvwxyz- '\n",
    "def sanitize(s):\n",
    "    return ''.join([c for c in s.lower() if c in charset_whitelist])\n",
    "\n",
    "sentences = [sanitize(d['sentence']) for d in dataset]\n",
    "print(f'{sentences[:3]=}')\n",
    "print(f'{max([len(s.split()) for s in sentences])=}')\n",
    "\n",
    "vocab = set([w for s in sentences for w in s.split()])\n",
    "print(f'{len(vocab)=} {list(vocab)[:3]=}')\n",
    "\n",
    "# The sample size for each word seems really small so this dataset probably won't work at all.\n",
    "# can I get a dataset specialized on fruits maybe, to do queries of the type `lemon - yellow + green = lime`\n",
    "queen = [s for s in sentences if 'queen' in s]\n",
    "print(f'{len(queen)=} {queen[:3]=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e8382d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encode(xs)=tensor([    1, 10912,  3840, 12269,  9667,  8109,     1,     1,     0])\n",
      "decode(encode(xs))='<???> for one welcome our new <???> <???> <end>'\n",
      "encode(xs)=tensor([8951, 4067,  614, 8951, 9491,    0])\n",
      "decode(encode(xs))='the chicken cross the road <end>'\n"
     ]
    }
   ],
   "source": [
    "vocab_list = ['<end>', '<???>'] + list(vocab)\n",
    "stoi = {w: i for i, w in enumerate(vocab_list)}\n",
    "itos = {i: w for w, i in stoi.items()}\n",
    "\n",
    "def encode(s):\n",
    "    return torch.tensor([stoi.get(w, 1) for w in sanitize(s).split() + ['<end>']], dtype=torch.long)\n",
    "\n",
    "def decode(t):\n",
    "    return ' '.join([itos[i.item()] for i in t])\n",
    "\n",
    "# careful here if we use words outside of vocab it'll explode\n",
    "for xs in ['I for one welcome our new robot overlords', 'The chicken cross the road']:\n",
    "    print(f'{encode(xs)=}')\n",
    "    print(f'{decode(encode(xs))=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "73f98650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) tensor([6255])\n",
      "decode(Xtrain[i])='<end> <end> <end> <end> <end> <end> <end> <end> <end> <end>' decode(Ytrain[i])='sepsis'\n",
      "tensor([   0,    0,    0,    0,    0,    0,    0,    0,    0, 6255]) tensor([8277])\n",
      "decode(Xtrain[i])='<end> <end> <end> <end> <end> <end> <end> <end> <end> sepsis' decode(Ytrain[i])='happens'\n",
      "tensor([   0,    0,    0,    0,    0,    0,    0,    0, 6255, 8277]) tensor([10733])\n",
      "decode(Xtrain[i])='<end> <end> <end> <end> <end> <end> <end> <end> sepsis happens' decode(Ytrain[i])='when'\n"
     ]
    }
   ],
   "source": [
    "# shape the data for training\n",
    "def chunk(s):\n",
    "    s = torch.cat((torch.zeros(block_size, dtype=torch.long), s))\n",
    "    for i in range(0, len(s) - block_size):\n",
    "        yield s[i: i + block_size], s[i + block_size: i + block_size + 1]\n",
    "\n",
    "chunked = [c for s in sentences for c in chunk(encode(s))]\n",
    "Xtrain = [c[0] for c in chunked]\n",
    "Ytrain = [c[1] for c in chunked]\n",
    "\n",
    "for i in range(3):\n",
    "    print(Xtrain[i], Ytrain[i])\n",
    "    print(f'{decode(Xtrain[i])=} {decode(Ytrain[i])=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "84bd70cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     0,     0,     0,     0,     0,     0,     0, 10070,  8209],\n",
      "        [    0,     0,     0,     0,     0, 10493,  9904,  6968,  1430,  5350]])\n",
      "tensor([[3971],\n",
      "        [7893]])\n",
      "<end> <end> <end> <end> <end> <end> <end> <end> most humans -> have\n",
      "<end> <end> <end> <end> <end> pyroelectricity is also a necessary -> consequence\n"
     ]
    }
   ],
   "source": [
    "def get_batch():\n",
    "    # TODO: swap between train and val\n",
    "    ix = torch.randint(len(Xtrain), (batch_size,))\n",
    "    x = torch.stack([Xtrain[i] for i in ix])\n",
    "    y = torch.stack([Ytrain[i] for i in ix])\n",
    "    # x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch()\n",
    "print(xb[:2])\n",
    "print(yb[:2])\n",
    "print(f'{decode(xb[0])} -> {decode(yb[0])}')\n",
    "print(f'{decode(xb[1])} -> {decode(yb[1])}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_hf_nlp",
   "language": "python",
   "name": "venv_hf_nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
